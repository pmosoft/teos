package com.sccomz.scala.test

import org.apache.hadoop.conf.Configuration
import org.apache.hadoop.fs.FileSystem
import org.apache.hadoop.fs.Path
import org.apache.hadoop.fs.permission.FsAction
import org.apache.hadoop.fs.permission.FsPermission
import org.apache.spark.SparkConf
import org.apache.spark.SparkContext
import org.apache.spark.sql.SparkSession
import org.apache.spark.sql.types.StringType
import org.apache.spark.sql.types.StructField
import org.apache.spark.sql.types.StructType
import scala.reflect.runtime.universe

object SparkSqlTest {
val spark = SparkSession.builder().appName("SparkSqlTest").getOrCreate()

def main(args: Array[String]): Unit = {
  //this.samToParquet(spark)
  //spark.stop();
}

def test01(spark: SparkSession) = {

spark.sql(s"""
SELECT BUILDING_INDEX -- 0
     , TBD_KEY        -- 1
     , NX             -- 2
     , NY             -- 3
     , FLOORZ         -- 4
     , EXT_SX         -- 5
     , EXT_SY         -- 7
     , NX*NY*FLOORZ      AS BIN_CNT
     , SUM(NX*NY*FLOORZ) OVER (ORDER BY BUILDING_INDEX) - NX*NY*FLOORZ      AS START_POINT_BIN
     ,(SUM(NX*NY*FLOORZ) OVER (ORDER BY BUILDING_INDEX) - NX*NY*FLOORZ) * 4 AS START_POINT_4BIN
FROM   RESULT_NR_BF_SCEN_HEADER
WHERE  SCHEDULE_ID = 8463235
ORDER BY BUILDING_INDEX
""").cache.createOrReplaceTempView("M_RESULT_NR_BF_SCEN_HEADER")
;

spark.sql(s"""
SELECT A.TBD_KEY
     , A.RX_FLOORZ
     , A.RX_TM_YPOS
     , A.RX_TM_XPOS
     , LOS AS VALUE
     , B.START_POINT_4BIN
     + (A.RX_FLOORZ*A.RX_TM_YPOS*A.RX_TM_XPOS*4)
     + (A.RX_TM_YPOS*A.RX_TM_XPOS*4)
     + (A.RX_TM_XPOS*4) AS POS
FROM   RESULT_NR_BF_LOS A
     , M_RESULT_NR_BF_SCEN_HEADER B
WHERE  A.SCHEDULE_ID = 8463235
AND    A.TBD_KEY = B.TBD_KEY
ORDER BY RX_FLOORZ, RX_TM_YPOS, RX_TM_XPOS
""").take(1000).foreach(println)
;


 
spark.sql(s"""
SELECT SCHEDULE_ID, COUNT(*) FROM RESULT_NR_BF_SCEN_HEADER GROUP BY SCHEDULE_ID 
""").take(1000).foreach(println);


}

def test02(spark: SparkSession) = {

spark.sql(s"""
SELECT BUILDING_INDEX
     , TBD_KEY
     , NX
     , NY
     , FLOORZ
     , EXT_SX
     , EXT_SY
     , NX*NY*FLOORZ      AS BIN_CNT
     , SUM(NX*NY*FLOORZ) OVER (ORDER BY BUILDING_INDEX) - NX*NY*FLOORZ AS START_POINT_BIN
FROM   RESULT_NR_BF_SCEN_HEADER
WHERE  SCHEDULE_ID = 8460965
ORDER BY BUILDING_INDEX
""").cache.createOrReplaceTempView("M_RESULT_NR_BF_SCEN_HEADER")
;


spark.sql(s"""
SELECT BUILDING_INDEX
--     , TBD_KEY
     , NX
     , NY
     , FLOORZ
--     , EXT_SX
--     , EXT_SY
     , NX*NY*FLOORZ AS BINCNT
     , SUM(NX*NY*FLOORZ) OVER (ORDER BY BUILDING_INDEX) - NX*NY*FLOORZ AS STARTPOINTBIN
FROM   M_RESULT_NR_BF_SCEN_HEADER
""").take(100).foreach(println);

spark.sql(s"""
WITH RU AS
(
SELECT B.SCHEDULE_ID, A.ENB_ID, A.PCI, A.PCI_PORT, A.RU_ID,
       A.X_BIN_CNT, A.Y_BIN_CNT,
       INT(A.SITE_STARTX) DIV A.RESOLUTION * A.RESOLUTION AS SITE_STARTX,
       INT(A.SITE_STARTY) DIV A.RESOLUTION * A.RESOLUTION AS SITE_STARTY,
       INT(A.SITE_ENDX) DIV A.RESOLUTION * A.RESOLUTION AS SITE_ENDX,
       INT(A.SITE_ENDY) DIV A.RESOLUTION * A.RESOLUTION AS SITE_ENDY,
       A.RESOLUTION
  FROM SCENARIO_NR_RU A, SCHEDULE B
 WHERE B.SCHEDULE_ID = 8463233
   AND A.SCENARIO_ID = B.SCENARIO_ID
)
SELECT RU_ID                                --0
     , X_BIN_CNT                            --1
     , Y_BIN_CNT                            --2
     , CAST(X_POINT AS INTEGER) AS X_POINT  --3
     , CAST(Y_POINT AS INTEGER) AS Y_POINT  --4
     , VALUE                                --5
FROM
(
SELECT DISTINCT
       A.RU_ID, B.X_BIN_CNT, B.Y_BIN_CNT,
       ((A.RX_TM_XPOS DIV B.RESOLUTION * B.RESOLUTION) - SITE_STARTX) DIV B.RESOLUTION AS X_POINT,
       ((A.RX_TM_YPOS DIV B.RESOLUTION * B.RESOLUTION) - SITE_STARTY) DIV B.RESOLUTION AS Y_POINT,
       VALUE
 FROM  RESULT_NR_2D_LOS_RU A, RU B
 WHERE A.SCHEDULE_ID = B.SCHEDULE_ID
   AND A.RU_ID       = B.RU_ID
   AND A.RU_ID       = '1012220451'
   AND A.SCHEDULE_ID = 8463233
   AND (A.RX_TM_XPOS DIV B.RESOLUTION * B.RESOLUTION) BETWEEN SITE_STARTX AND SITE_ENDX
   AND (A.RX_TM_YPOS DIV B.RESOLUTION * B.RESOLUTION) BETWEEN SITE_STARTY AND SITE_ENDY
   ORDER BY X_POINT, Y_POINT
)
WHERE X_POINT < X_BIN_CNT
AND   Y_POINT < Y_BIN_CNT
""").take(100).foreach(println);


spark.sql(s"""
SELECT CAST(1 AS INTEGER) AS X_POINT 
""").take(100).foreach(println);


spark.sql(s"""
SELECT RU_ID FROM RESULT_NR_2D_LOS_RU WHERE SCHEDULE_ID = 8463233
""").take(100).foreach(println);



spark.sql(s"""
SELECT B.SCHEDULE_ID, A.ENB_ID, A.PCI, A.PCI_PORT, A.RU_ID,
       A.X_BIN_CNT, A.Y_BIN_CNT,
       INT(A.SITE_STARTX) DIV A.RESOLUTION * A.RESOLUTION AS SITE_STARTX,
       INT(A.SITE_STARTY) DIV A.RESOLUTION * A.RESOLUTION AS SITE_STARTY,
       INT(A.SITE_ENDX) DIV A.RESOLUTION * A.RESOLUTION AS SITE_ENDX,
       INT(A.SITE_ENDY) DIV A.RESOLUTION * A.RESOLUTION AS SITE_ENDY,
       A.RESOLUTION
  FROM SCENARIO_NR_RU A, SCHEDULE B
 WHERE B.SCHEDULE_ID = 8463233
   AND A.SCENARIO_ID = B.SCENARIO_ID
""").take(100).foreach(println)
;


spark.sql(s"""
SELECT * FROM RESULT_NR_BF_SCEN_HEADER WHERE SCHEDULE_ID = 8460965
""").take(100).foreach(println);

spark.sql(s"""
SELECT COUNT(*) FROM RESULT_NR_BF_LOS_RU WHERE SCHEDULE_ID = 8463235
""").take(100).foreach(println);

spark.sql(s"""
SELECT DISTINCT RU_ID FROM RESULT_NR_BF_LOS_RU WHERE SCHEDULE_ID = 8463235
""").take(100).foreach(println);

spark.sql(s"""
SELECT COUNT(DISTINCT RU_ID) FROM RESULT_NR_BF_LOS_RU WHERE SCHEDULE_ID = 8463235
""").take(100).foreach(println);

// 5,156,492,021


//RESULT_NR_BF_LOS_RU_8463235_1012138268



val sqlDf = spark.sql(s"""
WITH RU AS
(
SELECT B.SCHEDULE_ID, A.ENB_ID, A.PCI, A.PCI_PORT, A.RU_ID,
       A.X_BIN_CNT, A.Y_BIN_CNT,
       INT(A.SITE_STARTX) DIV A.RESOLUTION * A.RESOLUTION AS SITE_STARTX,
       INT(A.SITE_STARTY) DIV A.RESOLUTION * A.RESOLUTION AS SITE_STARTY,
       INT(A.SITE_ENDX) DIV A.RESOLUTION * A.RESOLUTION AS SITE_ENDX,
       INT(A.SITE_ENDY) DIV A.RESOLUTION * A.RESOLUTION AS SITE_ENDY,
       A.RESOLUTION,
       CONCAT(B.USER_ID,'/',A.SCENARIO_ID) AS SECTOR_PATH,
       CONCAT(B.USER_ID,'/',A.SCENARIO_ID,'/ENB_',A.ENB_ID,'/PCI_',A.PCI,'_PORT_',A.PCI_PORT,'_',A.RU_ID) AS RU_PATH
  FROM SCENARIO_NR_RU A, SCHEDULE B
 WHERE B.SCHEDULE_ID = 8463233
   AND A.SCENARIO_ID = B.SCENARIO_ID
)
SELECT RU_ID                                --0
     , X_BIN_CNT                            --1
     , Y_BIN_CNT                            --2
     , CAST(X_POINT AS INTEGER) AS X_POINT  --3
     , CAST(Y_POINT AS INTEGER) AS Y_POINT  --4
     , VALUE                                --5
     , RU_PATH                              --6  
FROM
(
SELECT DISTINCT
       A.RU_ID, B.X_BIN_CNT, B.Y_BIN_CNT,
       ((A.RX_TM_XPOS DIV B.RESOLUTION * B.RESOLUTION) - SITE_STARTX) DIV B.RESOLUTION AS X_POINT,
       ((A.RX_TM_YPOS DIV B.RESOLUTION * B.RESOLUTION) - SITE_STARTY) DIV B.RESOLUTION AS Y_POINT,
       VALUE AS VALUE,
       B.RU_PATH
 FROM  RESULT_NR_2D_LOS_RU A, RU B
 WHERE A.SCHEDULE_ID = B.SCHEDULE_ID
   AND A.RU_ID       = B.RU_ID
   AND A.SCHEDULE_ID = 8463233
   AND (A.RX_TM_XPOS DIV B.RESOLUTION * B.RESOLUTION) BETWEEN SITE_STARTX AND SITE_ENDX
   AND (A.RX_TM_YPOS DIV B.RESOLUTION * B.RESOLUTION) BETWEEN SITE_STARTY AND SITE_ENDY
   ORDER BY X_POINT, Y_POINT
)
WHERE X_POINT < X_BIN_CNT
AND   Y_POINT < Y_BIN_CNT
"""); sqlDf.cache.createOrReplaceTempView("RU_BIN"); sqlDf.count();

spark.sql("DROP TABLE IF EXISTS M_RU_BIN2");

spark.sql(s"""
SELECT RU_ID 
     , MAX(X_BIN_CNT) AS MAX_X_BIN_CNT  
     , MAX(Y_BIN_CNT) AS MAX_Y_BIN_CNT 
     , MIN(X_POINT)   AS MIN_X_POINT
     , MAX(X_POINT)   AS MAX_X_POINT
     , MIN(Y_POINT)   AS MIN_Y_POINT
     , MAX(Y_POINT)   AS MAX_Y_POINT 
FROM M_RU_BIN
GROUP BY RU_ID
""").cache.createOrReplaceTempView("M_RU_BIN2")

spark.sql(s"""
SELECT * FROM M_RU_BIN2
""").take(100).foreach(println);

spark.sql(s"""
SELECT * 
FROM   M_RU_BIN2
WHERE  MAX_X_POINT >= MAX_X_BIN_CNT 
""").take(100).foreach(println);

spark.sql(s"""
SELECT * 
FROM   M_RU_BIN2
WHERE  MAX_Y_POINT >= MAX_Y_BIN_CNT 
""").take(100).foreach(println);


spark.sql(s"""
SELECT COUNT(*) FROM   NRSECTORPARAMETER
WHERE  SCENARIO_ID  = 5113566
""").take(100).foreach(println);






spark.sql(s"""
INSERT INTO SCHEDULE PARTITION (SCHEDULE_ID=8460062) 
SELECT 
  TYPE_CD                  
, SCENARIO_ID              
, USER_ID                  
, PRIORITIZE               
, PROCESS_CD               
, PROCESS_MSG              
, SCENARIO_PATH            
, REG_DT                   
, MODIFY_DT                
, RETRY_CNT                
, SERVER_ID                
, BIN_X_CNT                
, BIN_Y_CNT                
, RU_CNT                   
, ANALYSIS_WEIGHT          
, PHONE_NO                 
, RESULT_TIME              
, TILT_PROCESS_TYPE        
, GEOMETRYQUERY_SCHEDULE_ID
, RESULT_BIT               
, INTERWORKING_INFO        
FROM SCHEDULE_B
""").take(100).foreach(println);



}  


def test03(spark: SparkSession) = {

  
  
spark.sql(s"""
WITH RU AS
(
SELECT B.SCHEDULE_ID, A.ENB_ID, A.PCI, A.PCI_PORT, A.RU_ID,
       A.X_BIN_CNT, A.Y_BIN_CNT,
       INT(A.SITE_STARTX) DIV A.RESOLUTION * A.RESOLUTION AS SITE_STARTX,
       INT(A.SITE_STARTY) DIV A.RESOLUTION * A.RESOLUTION AS SITE_STARTY,
       INT(A.SITE_ENDX) DIV A.RESOLUTION * A.RESOLUTION AS SITE_ENDX,
       INT(A.SITE_ENDY) DIV A.RESOLUTION * A.RESOLUTION AS SITE_ENDY,
       A.RESOLUTION
  FROM SCENARIO_NR_RU A, SCHEDULE B
 WHERE B.SCHEDULE_ID = 8460062
   AND A.RU_ID = 1012242300
   AND A.SCENARIO_ID = B.SCENARIO_ID
)
SELECT X_POINT,VALUE, COUNT(*)
FROM (
SELECT A.SCHEDULE_ID,
       B.ENB_ID, B.PCI, B.PCI_PORT, B.RU_ID,  B.X_BIN_CNT, B.Y_BIN_CNT,
       ((A.RX_TM_XPOS DIV B.RESOLUTION * B.RESOLUTION) - SITE_STARTX) DIV B.RESOLUTION AS X_POINT,
       ((A.RX_TM_YPOS DIV B.RESOLUTION * B.RESOLUTION) - SITE_STARTY) DIV B.RESOLUTION AS Y_POINT,
       A.VALUE
  FROM RESULT_NR_2D_LOS_RU A, RU B
 WHERE A.SCHEDULE_ID = B.SCHEDULE_ID
   AND A.RU_ID = B.RU_ID
   AND A.SCHEDULE_ID = 8460062
   AND A.RU_ID = 1012242300
   AND (A.RX_TM_XPOS DIV B.RESOLUTION * B.RESOLUTION) BETWEEN SITE_STARTX AND SITE_ENDX
   AND (A.RX_TM_YPOS DIV B.RESOLUTION * B.RESOLUTION) BETWEEN SITE_STARTY AND SITE_ENDY
   ORDER BY X_POINT, Y_POINT
)
GROUP BY X_POINT,VALUE
ORDER BY X_POINT,VALUE
""").take(1000).foreach(println);


spark.sql(s"""
SELECT *
 FROM  RESULT_NR_2D_LOS_RU A
 WHERE A.SCHEDULE_ID = 8460062
   AND A.RU_ID = 1012242308
""").take(100).foreach(println);




spark.sql(s"""
SELECT COUNT(*)
  FROM SCENARIO_NR_RU A, SCHEDULE B
 WHERE B.SCHEDULE_ID = 8460062
   AND A.SCENARIO_ID = B.SCENARIO_ID
""").take(100).foreach(println);

spark.sql(s"""
SELECT B.SCHEDULE_ID, A.ENB_ID, A.PCI, A.PCI_PORT, A.RU_ID,
       A.X_BIN_CNT, A.Y_BIN_CNT,
       INT(A.SITE_STARTX) DIV A.RESOLUTION * A.RESOLUTION AS SITE_STARTX,
       INT(A.SITE_STARTY) DIV A.RESOLUTION * A.RESOLUTION AS SITE_STARTY,
       INT(A.SITE_ENDX) DIV A.RESOLUTION * A.RESOLUTION AS SITE_ENDX,
       INT(A.SITE_ENDY) DIV A.RESOLUTION * A.RESOLUTION AS SITE_ENDY,
       A.RESOLUTION
  FROM SCENARIO_NR_RU A, SCHEDULE B
 WHERE B.SCHEDULE_ID = 8460062
   AND A.RU_ID = 1012242300
   AND A.SCENARIO_ID = B.SCENARIO_ID
""").take(100).foreach(println);



spark.sql(s"""
WITH RU AS
(
SELECT B.SCHEDULE_ID, A.ENB_ID, A.PCI, A.PCI_PORT, A.RU_ID,
       A.X_BIN_CNT, A.Y_BIN_CNT,
       INT(A.SITE_STARTX) DIV A.RESOLUTION * A.RESOLUTION AS SITE_STARTX,
       INT(A.SITE_STARTY) DIV A.RESOLUTION * A.RESOLUTION AS SITE_STARTY,
       INT(A.SITE_ENDX) DIV A.RESOLUTION * A.RESOLUTION AS SITE_ENDX,
       INT(A.SITE_ENDY) DIV A.RESOLUTION * A.RESOLUTION AS SITE_ENDY,
       A.RESOLUTION
  FROM SCENARIO_NR_RU A, SCHEDULE B
 WHERE B.SCHEDULE_ID = 8460062
   AND A.RU_ID = 1012242300
   AND A.SCENARIO_ID = B.SCENARIO_ID
)
SELECT A.SCHEDULE_ID,
       B.ENB_ID, B.PCI, B.PCI_PORT, B.RU_ID,  B.X_BIN_CNT, B.Y_BIN_CNT,
       ((A.RX_TM_XPOS DIV B.RESOLUTION * B.RESOLUTION) - SITE_STARTX) DIV B.RESOLUTION AS X_POINT,
       ((A.RX_TM_YPOS DIV B.RESOLUTION * B.RESOLUTION) - SITE_STARTY) DIV B.RESOLUTION AS Y_POINT,
       A.VALUE
  FROM RESULT_NR_2D_LOS_RU A, RU B
 WHERE A.SCHEDULE_ID = B.SCHEDULE_ID
   AND A.RU_ID = B.RU_ID
   AND A.SCHEDULE_ID = 8460062
   AND A.RU_ID = 1012242300
   AND (A.RX_TM_XPOS DIV B.RESOLUTION * B.RESOLUTION) BETWEEN SITE_STARTX AND SITE_ENDX
   AND (A.RX_TM_YPOS DIV B.RESOLUTION * B.RESOLUTION) BETWEEN SITE_STARTY AND SITE_ENDY
   ORDER BY X_POINT, Y_POINT
""").take(1000).foreach(println);


spark.sql(s"""
SELECT * 
FROM   SCENARIO_NR_RU 
WHERE  SCENARIO_ID = (SELECT SCENARIO_ID FROM I_SCHEDULE WHERE SCHEDULE_ID = 8460062)
AND    RU_ID = 1012242300 
""").take(1000).foreach(println);

spark.sql(s"""
SELECT RX_TM_XPOS, RX_TM_YPOS, VALUE 
FROM   RESULT_NR_2D_LOS_RU 
WHERE  SCENARIO_ID = (SELECT SCENARIO_ID FROM I_SCHEDULE WHERE SCHEDULE_ID = 8460062)
AND    RU_ID = 1012242300
ORDER BY RX_TM_XPOS, RX_TM_YPOS 
""").take(1000).foreach(println);



spark.sql(s"""
		WITH RU AS
		(
		SELECT B.SCHEDULE_ID, A.ENB_ID, A.PCI, A.PCI_PORT, A.RU_ID,
		A.X_BIN_CNT, A.Y_BIN_CNT,
		INT(A.SITE_STARTX) DIV A.RESOLUTION * A.RESOLUTION AS SITE_STARTX,
		INT(A.SITE_STARTY) DIV A.RESOLUTION * A.RESOLUTION AS SITE_STARTY,
		INT(A.SITE_ENDX) DIV A.RESOLUTION * A.RESOLUTION AS SITE_ENDX,
		INT(A.SITE_ENDY) DIV A.RESOLUTION * A.RESOLUTION AS SITE_ENDY,
		A.RESOLUTION
		FROM SCENARIO_NR_RU A, SCHEDULE B
		WHERE B.SCHEDULE_ID = 8460062
		AND A.SCENARIO_ID = B.SCENARIO_ID
		AND A.RU_ID = 1012242300
		)
		SELECT A.SCHEDULE_ID,
		B.ENB_ID, B.PCI, B.PCI_PORT, B.RU_ID,  B.X_BIN_CNT, B.Y_BIN_CNT,
		((A.RX_TM_XPOS DIV B.RESOLUTION * B.RESOLUTION) - SITE_STARTX) DIV B.RESOLUTION AS X_POINT,
		((A.RX_TM_YPOS DIV B.RESOLUTION * B.RESOLUTION) - SITE_STARTY) DIV B.RESOLUTION AS Y_POINT,
		A.VALUE
		FROM RESULT_NR_2D_LOS_RU A, RU B
		WHERE A.SCHEDULE_ID = 8460062
		AND A.SCHEDULE_ID = B.SCHEDULE_ID
		AND A.RU_ID = B.RU_ID
		AND A.RU_ID = 1012242300
		AND (A.RX_TM_XPOS DIV B.RESOLUTION * B.RESOLUTION) BETWEEN SITE_STARTX AND SITE_ENDX
		AND (A.RX_TM_YPOS DIV B.RESOLUTION * B.RESOLUTION) BETWEEN SITE_STARTY AND SITE_ENDY
		ORDER BY X_POINT, Y_POINT
		""").take(2000).foreach(println);
}  


  
}

