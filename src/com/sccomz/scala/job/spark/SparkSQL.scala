package com.sccomz.scala.job.spark

import org.apache.spark.sql.SparkSession

object SparkSQL {
  var spark: SparkSession = null
  
  def main(args: Array[String]): Unit = {
    spark = SparkSession.builder().appName("Los").getOrCreate();
    spark.sql(s"""
WITH RU AS
(
SELECT B.SCHEDULE_ID, A.ENB_ID, A.PCI, A.PCI_PORT, A.RU_ID,
       A.X_BIN_CNT, A.Y_BIN_CNT,
       INT(A.SITE_STARTX) DIV (A.RESOLUTION * A.RESOLUTION) AS SITE_STARTX,
       INT(A.SITE_STARTY) DIV (A.RESOLUTION * A.RESOLUTION) AS SITE_STARTY,
       INT(A.SITE_ENDX) DIV (A.RESOLUTION * A.RESOLUTION) AS SITE_ENDX,
       INT(A.SITE_ENDY) DIV (A.RESOLUTION * A.RESOLUTION) AS SITE_ENDY,
       A.RESOLUTION
  FROM SCENARIO_NR_RU A, SCHEDULE B
 WHERE B.SCHEDULE_ID = 8460062
   AND A.SCENARIO_ID = B.SCENARIO_ID
)
SELECT A.SCHEDULE_ID,
       B.ENB_ID, B.PCI, B.PCI_PORT, B.RU_ID,  B.X_BIN_CNT, B.Y_BIN_CNT,
       (((A.RX_TM_XPOS DIV (B.RESOLUTION * B.RESOLUTION)) - SITE_STARTX) DIV B.RESOLUTION) AS X_POINT,
       (((A.RX_TM_YPOS DIV (B.RESOLUTION * B.RESOLUTION)) - SITE_STARTY) DIV B.RESOLUTION) AS Y_POINT,
       value
 FROM  RESULT_NR_2D_LOS_RU A, RU B
 WHERE A.SCHEDULE_ID = 8460062
   AND A.SCHEDULE_ID = B.SCHEDULE_ID
   AND A.RU_ID = B.RU_ID
   AND A.RU_ID = 1012242300
   AND (A.RX_TM_XPOS DIV (B.RESOLUTION * B.RESOLUTION)) BETWEEN SITE_STARTX AND SITE_ENDX
   AND (A.RX_TM_YPOS DIV (B.RESOLUTION * B.RESOLUTION)) BETWEEN SITE_STARTY AND SITE_ENDY
 ORDER BY X_POINT, Y_POINT
""").take(100).foreach(println);
  }
}